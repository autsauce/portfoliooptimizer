{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'rTNPVlyJyOJz5PYl4Y1J21uvY9qfujuA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "class PortfolioOptimizer:\n",
    "    \"\"\"A class to handle portfolio optimization using the Portfolio Optimizer API.\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the PortfolioOptimizer class.\n",
    "        \n",
    "        :param api_key: The API key for Portfolio Optimizer API, defaults to None.\n",
    "        :type api_key: str, optional\n",
    "        \"\"\"\n",
    "        self._api_key = api_key\n",
    "        self._base_url = 'https://api.portfoliooptimizer.io/v1'\n",
    "        self._returns = pd.DataFrame()\n",
    "        self._headers = {}\n",
    "        if self._api_key:\n",
    "            self._headers[\"X-API-Key\"] = self._api_key\n",
    "\n",
    "    def get_api_limits(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Gets the limits of the Portfolio Optimizer API.\n",
    "        \n",
    "        :return: A dictionary containing the API status headers.\n",
    "        :rtype: Dict[str, Any]\n",
    "        \"\"\"\n",
    "\n",
    "        response = requests.request(\n",
    "            method='GET', url=self._base_url, headers=self._headers)\n",
    "        return dict(response.headers)\n",
    "\n",
    "    def _make_request(self, endpoint: str, method: str = \"GET\", params: Dict[str, Any] = None, data: Dict[str, Any] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Makes an HTTP request to the Portfolio Optimizer API.\n",
    "        \n",
    "        :param endpoint: The API endpoint to call.\n",
    "        :type endpoint: str\n",
    "        :param method: The HTTP method to use, defaults to \"GET\".\n",
    "        :type method: str, optional\n",
    "        :param params: URL parameters for the API call, defaults to None.\n",
    "        :type params: Dict[str, Any], optional\n",
    "        :param data: JSON data to send with the request, defaults to None.\n",
    "        :type data: Dict[str, Any], optional\n",
    "        :return: The API response as a dictionary.\n",
    "        :rtype: Dict[str, Any]\n",
    "        \"\"\"\n",
    "\n",
    "        url = f\"{self._base_url}{endpoint}\"\n",
    "        response = requests.request(\n",
    "            method, url, headers=self._headers, params=params, json=data)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(response.text)\n",
    "            response.raise_for_status()\n",
    "\n",
    "    def _get_asset_prices(self, symbols: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves historical prices for the given symbols.\n",
    "        \n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :return: DataFrame containing historical prices.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        prices = yf.download(tickers=symbols, ignore_tz=True,\n",
    "                             progress=False, auto_adjust=True)[\"Close\"]\n",
    "        equities = [s for s in symbols if '-' not in s]\n",
    "\n",
    "        if equities:\n",
    "            prices.dropna(axis=0, how='all', subset=equities, inplace=True)\n",
    "\n",
    "        if prices.iloc[-1].isna().sum() != 0:\n",
    "            prices = prices.iloc[:-1, :]\n",
    "\n",
    "        prices.index = pd.to_datetime(prices.index).rename(\"date\")\n",
    "        return prices\n",
    "\n",
    "    def _get_asset_returns(self, symbols: List[str], lookback: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves historical returns for the given symbols.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :return: DataFrame containing historical returns.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not all(s in self._returns.columns for s in symbols) or any(self._returns[s].tail(lookback).isna().sum() >= lookback for s in symbols):\n",
    "            self._returns = self._get_asset_prices(symbols).pct_change(1)\n",
    "        \n",
    "        nan_columns = self._returns.columns[self._returns.tail(lookback).isna().any()].tolist()\n",
    "        if nan_columns:\n",
    "            raise ValueError(f'''Yahoo Finance did not have enough historical data available based on the specified lookback period for the following symbols: {nan_columns}.\n",
    "            Try the following options to correct this issue:\n",
    "            1. Decrease the lookback period.\n",
    "            2. Verify that the provided symbols are correct and supported by Yahoo.\n",
    "            3. Provide a custom returns DataFrame with enough data for your desired lookback period.''')\n",
    "            \n",
    "        return self._returns\n",
    "\n",
    "    def _validate_returns_format(self, returns: pd.DataFrame, symbols: List[str], lookback: int) -> bool:\n",
    "        \"\"\"\n",
    "        Validates the provided returns DataFrame.\n",
    "\n",
    "        :param returns: DataFrame containing historical returns.\n",
    "        :type returns: pd.DataFrame\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :return: True if the returns DataFrame is valid, False otherwise.\n",
    "        :rtype: bool\n",
    "        \"\"\"\n",
    "        if returns is None:\n",
    "            return False\n",
    "\n",
    "        if not isinstance(returns, pd.DataFrame):\n",
    "            print('Warning: The data passed for returns is not a pandas DataFrame. Defaulting to Yahoo Finance for returns data.')\n",
    "            return False\n",
    "\n",
    "        if not set(symbols).issubset(set(returns.columns)):\n",
    "            print('Warning: The symbols passed do not all exist in the DataFrame columns that was provided for returns. Defaulting to Yahoo Finance for returns data.')\n",
    "            return False\n",
    "\n",
    "        if len(returns) < lookback:\n",
    "            print('Warning: The DataFrame that was provided for returns does not have enough rows for the specified lookback period. Defaulting to Yahoo Finance for returns data.')\n",
    "            return False\n",
    "\n",
    "        for col in returns.columns.tolist():\n",
    "            non_nan_values = returns[col].dropna()\n",
    "            if len(non_nan_values) < lookback:\n",
    "                print('Warning: The DataFrame provided for returns does not have enough non-NaN values in each column for the specified lookback period. Defaulting to Yahoo Finance for returns data.')\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _get_position_history(self, symbols: List[str], lookback: int, frequency: str = 'month_start', method: str = 'any', returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "                    \"\"\"\n",
    "                    Returns a DataFrame containing the position history of the given symbols, filtered by lookback and returns DataFrame.\n",
    "\n",
    "                    :param symbols: List of stock symbols.\n",
    "                    :type symbols: List[str]\n",
    "                    :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "                    :type lookback: int\n",
    "                    :param returns: DataFrame containing historical returns of the symbols.\n",
    "                    :type returns: pd.DataFrame\n",
    "                    :return: DataFrame containing the position history of the given symbols.\n",
    "                    :rtype: pd.DataFrame\n",
    "                    \"\"\"\n",
    "                    if not self._validate_returns_format(returns, symbols, lookback):\n",
    "                        returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "                    returns = returns[symbols].copy()\n",
    "\n",
    "                    df = []\n",
    "                    for date in returns.index:\n",
    "                        valid_symbols = [s for s in symbols if pd.notna(returns.loc[:date, s]).tail(lookback + 1).all()]\n",
    "                        df.append([date] + valid_symbols)\n",
    "\n",
    "                    df = pd.DataFrame(df)\n",
    "                    df.columns = ['date'] + [f'position_{i + 1}' for i in range(df.shape[1] - 1)]\n",
    "                    df.set_index('date', inplace=True)\n",
    "\n",
    "                    if method == 'any':\n",
    "                        df = df.loc[df.T.notna().sum()[df.T.notna().sum() > 1].index].copy()\n",
    "                    elif method == 'all':\n",
    "                        df.dropna(inplace=True)\n",
    "\n",
    "                    frequencies = {'week_start': 'W-MON',\n",
    "                                    'week_end': 'W-FRI',\n",
    "                                    'month_start': 'MS',\n",
    "                                    'month_end': 'M',\n",
    "                                    'quarter_start': 'QS-JAN',\n",
    "                                    'quarter_end': 'QS-DEC',\n",
    "                                    'year_start': 'AS-JAN',\n",
    "                                    'year_end': 'AS-DEC'}\n",
    "\n",
    "                    freq = frequencies.get(frequency)\n",
    "\n",
    "                    if frequency == 'day':\n",
    "                        rebalance_days = df.index.tolist()\n",
    "\n",
    "                    elif 'end' in frequency:\n",
    "                        date_range = pd.date_range(df.index.min(),df.index.max(),freq=freq)\n",
    "                        rebalance_days = []\n",
    "\n",
    "                        for i in range(0,len(date_range)):\n",
    "                            rebalance_days.append(df.loc[:date_range[i]].index.max())\n",
    "\n",
    "                    elif 'start' in frequency:\n",
    "                        date_range = pd.date_range(df.index.min(),df.index.max(),freq=freq)\n",
    "                        rebalance_days = []\n",
    "\n",
    "                        for i in range(0,len(date_range)):\n",
    "                            rebalance_days.append(df.loc[date_range[i]:].index.min())\n",
    "\n",
    "                    else:\n",
    "                        raise ValueError('Invalid frequency. Valid frequencies are: day, week_start, week_end, month_start, month_end, quarter_start, quarter_end, year_start, year_end.')\n",
    "\n",
    "                    df = df.loc[rebalance_days]\n",
    "\n",
    "                    return df\n",
    "\n",
    "    def _generate_portfolio_equity_curve(self,weights_history: pd.DataFrame, returns: pd.DataFrame, start_equity: float = 100000, fee: float = 0.0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generates the equity curve for a portfolio given its weights history and returns data.\n",
    "\n",
    "        Parameters:\n",
    "        weights_history (pd.DataFrame): A dataframe containing the weights history for each asset in the portfolio.\n",
    "        returns (pd.DataFrame): A dataframe containing the returns data for each asset in the portfolio.\n",
    "        start_equity (float): The starting equity of the portfolio (default is 100000).\n",
    "        fee (float): The trading fee for the portfolio (default is 0.0).\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A dataframe containing the equity curve for the portfolio.\n",
    "        \"\"\"\n",
    "        \n",
    "        symbols = weights_history[[c for c in weights_history.columns if c.startswith('position_')]].unstack().unique().tolist()\n",
    "        symbols = [s for s in symbols if s is not None]\n",
    "        n = len(symbols)\n",
    "        rebalance_days = weights_history.index.tolist()\n",
    "\n",
    "        df = returns.index.to_frame().set_index('date').join(weights_history,how='left').loc[weights_history.index.min():].ffill()\n",
    "\n",
    "        positions_columns = [f'position_{i + 1}' for i in range(n)]\n",
    "        weights_columns = [f'weight_{i + 1}' for i in range(n)]\n",
    "        values_columns = [f'value_{i + 1}' for i in range(n)]\n",
    "        returns_columns = [f'returns_{i + 1}' for i in range(n)]\n",
    "\n",
    "        for i in range(0,len(df.index.values)):\n",
    "            today = df.index[i]\n",
    "            cp = df.loc[today,positions_columns].dropna().tolist()\n",
    "            if today == df.index.min():\n",
    "                e = start_equity\n",
    "                w = df.loc[today,weights_columns].values\n",
    "                r = returns.loc[today,cp].values\n",
    "                s = n - r.size\n",
    "                if s > 0:\n",
    "                    r = np.pad(r,(0,s))\n",
    "                df.loc[today,returns_columns] = r\n",
    "                v = (e * w * (r+1))\n",
    "                df.loc[today,values_columns] = v\n",
    "                df.loc[today,'portfolio_equity_curve'] = sum(v)\n",
    "\n",
    "            elif today in rebalance_days:\n",
    "                yday = df.index[i-1]\n",
    "                e = df.loc[yday,'portfolio_equity_curve'] * (1-(fee/12))\n",
    "                w = df.loc[today,weights_columns].values\n",
    "                r = returns.loc[today,cp].values\n",
    "                s = n - r.size\n",
    "                if s > 0:\n",
    "                    r = np.pad(r,(0,s))\n",
    "                df.loc[today,returns_columns] = r\n",
    "                v = (e * w * (r+1))\n",
    "                df.loc[today,values_columns] = v\n",
    "                df.loc[today,'portfolio_equity_curve'] = sum(v)\n",
    "                \n",
    "            else:\n",
    "                yday = df.index[i-1]\n",
    "                r = returns.loc[today,cp].values\n",
    "                s = n - r.size\n",
    "                if s > 0:\n",
    "                    r = np.pad(r,(0,s))\n",
    "                df.loc[today,returns_columns] = r\n",
    "                v = (df.loc[yday,values_columns] * (r+1))\n",
    "                df.loc[today,values_columns] = v\n",
    "                df.loc[today,'portfolio_equity_curve'] = sum(v)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _generate_benchmark_equity_curve(self,\n",
    "        benchmark: str,\n",
    "        start_equity: float,\n",
    "        start_date: str,\n",
    "        end_date: str\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Generates a benchmark equity curve based on a provided ticker symbol and date range.\n",
    "\n",
    "        :param benchmark: Ticker symbol for the benchmark index or stock.\n",
    "        :type benchmark: str\n",
    "        :param start_equity: Starting equity value.\n",
    "        :type start_equity: float\n",
    "        :param start_date: Start date for the equity curve in the format \"YYYY-MM-DD\".\n",
    "        :type start_date: str\n",
    "        :param end_date: End date for the equity curve in the format \"YYYY-MM-DD\".\n",
    "        :type end_date: str\n",
    "        :return: Cumulative return of the benchmark equity curve.\n",
    "        :rtype: pd.Series\n",
    "        \"\"\"\n",
    "        returns = yf.download(\n",
    "            tickers=benchmark,\n",
    "            ignore_tz=True,\n",
    "            auto_adjust=True,\n",
    "            progress=False\n",
    "        )['Close'].pct_change().dropna() + 1\n",
    "        \n",
    "        equity_curve = (returns.loc[start_date:end_date].cumprod() * start_equity).rename('benchmark_equity_curve')\n",
    "        equity_curve.index = equity_curve.index.rename('date')\n",
    "        \n",
    "        return equity_curve\n",
    "\n",
    "    def _get_covariance_matrix(self, symbols: List[str], lookback: int, returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves the covariance matrix of the given symbols.\n",
    "        \n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The covariance matrix as a DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols,lookback)\n",
    "\n",
    "        returns = returns[symbols].tail(lookback)\n",
    "        matrix = returns.cov()\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def _get_exponential_covariance_matrix(self, symbols: List[str], lookback: int, decay_factor: float, returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves the exponentially weighted covariance matrix for a list of assets.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting, between 0 and 1.\n",
    "        :type decay_factor: float\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The exponentially weighted covariance matrix as a DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols,lookback)\n",
    "\n",
    "        returns = returns[symbols].tail(lookback)\n",
    "\n",
    "        data = {\n",
    "            \"assets\": [\n",
    "                {\"assetReturns\": returns[col].tolist()}\n",
    "                for col in returns.columns\n",
    "            ],\n",
    "            \"decayFactor\": decay_factor\n",
    "        }\n",
    "\n",
    "        response = self._make_request(\n",
    "            '/assets/covariance/matrix/exponentially-weighted', method='POST', data=data)\n",
    "        matrix = pd.DataFrame(\n",
    "            response['assetsCovarianceMatrix'], index=symbols, columns=symbols)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def construct_equal_risk_contributions_portfolio(self,\n",
    "                                           symbols: List[str],\n",
    "                                           lookback: int,\n",
    "                                           covariance_type: str = 'standard',\n",
    "                                           decay_factor: float = 0.94,\n",
    "                                           returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculates an equal risk contributions portfolio for the given symbols using the Portfolio Optimizer API.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param covariance_type: The type of covariance matrix to use. Either 'standard' or 'exponential'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting, between 0 and 1. Only used if covariance_type='exponential'.\n",
    "        :type decay_factor: float, optional\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The optimized portfolio weights as a Pandas DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols,lookback)\n",
    "\n",
    "        if covariance_type == 'standard':\n",
    "            matrix = self._get_covariance_matrix(symbols, lookback, returns)\n",
    "        elif covariance_type == 'exponential':\n",
    "            matrix = self._get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "        else:\n",
    "            raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "        data = {\n",
    "            \"assets\": len(symbols),\n",
    "            \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "            \"constraints\": {}\n",
    "        }\n",
    "\n",
    "        endpoint = \"/portfolio/optimization/equal-risk-contributions\"\n",
    "        response = self._make_request(endpoint, method=\"POST\", data=data)\n",
    "\n",
    "        weights = response['assetsWeights']\n",
    "        df = pd.DataFrame({'symbol': symbols, 'weight': weights}).set_index('symbol')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def construct_hierarchical_risk_parity_portfolio(self, symbols: List[str],\n",
    "                                           lookback: int,\n",
    "                                           covariance_type: str = 'standard',\n",
    "                                           decay_factor: float = 0.94,\n",
    "                                           returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculates a hierarchical risk parity portfolio for the given symbols using the Portfolio Optimizer API.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param covariance_matrix_type: Optional type of covariance matrix to use, either 'standard' or 'exponential', defaults to 'standard'.\n",
    "        :type covariance_matrix_type: str, optional\n",
    "        :param decay_factor: Optional decay factor for the exponentially weighted covariance matrix, defaults to None.\n",
    "        :type decay_factor: float, optional\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The optimized portfolio weights as a Pandas DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols,lookback)\n",
    "\n",
    "        if covariance_type == 'standard':\n",
    "            matrix = self._get_covariance_matrix(symbols, lookback, returns)\n",
    "        elif covariance_type == 'exponential':\n",
    "            matrix = self._get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "        else:\n",
    "            raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "        data = {\n",
    "            \"assets\": len(symbols),\n",
    "            \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "            \"constraints\": {}\n",
    "        }\n",
    "\n",
    "        endpoint = \"/portfolio/optimization/hierarchical-risk-parity\"\n",
    "        response = self._make_request(endpoint, method=\"POST\", data=data)\n",
    "\n",
    "        weights = response['assetsWeights']\n",
    "        df = pd.DataFrame({'symbol': symbols, 'weight': weights}).set_index('symbol')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def construct_hierarchical_risk_parity_cluster_based(self, symbols: List[str], lookback: int,\n",
    "                                               covariance_type: str = 'standard', decay_factor: float = 0.94,\n",
    "                                               returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculates a hierarchical risk parity clustering-based portfolio for the given symbols using the Portfolio Optimizer API.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param covariance_type: The type of covariance matrix to use, either 'standard' or 'exponential', defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting, between 0 and 1, defaults to None.\n",
    "        :type decay_factor: float, optional\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The optimized portfolio weights as a Pandas DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols,lookback)\n",
    "\n",
    "        if covariance_type == 'standard':\n",
    "            matrix = self._get_covariance_matrix(symbols, lookback, returns)\n",
    "        elif covariance_type == 'exponential':\n",
    "            matrix = self._get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "        else:\n",
    "            raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "        data = {\n",
    "            \"assets\": len(symbols),\n",
    "            \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "            \"constraints\": {}\n",
    "        }\n",
    "\n",
    "        endpoint = \"/portfolio/optimization/hierarchical-risk-parity/clustering-based\"\n",
    "        response = self._make_request(endpoint, method=\"POST\", data=data)\n",
    "\n",
    "        weights = response['assetsWeights']\n",
    "        df = pd.DataFrame(\n",
    "            {'symbol': symbols, 'weight': weights}).set_index('symbol')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def construct_most_diversified_portfolio(self, symbols: List[str], lookback: int,\n",
    "                                covariance_type: str = 'standard',\n",
    "                                decay_factor: float = 0.94,\n",
    "                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculates the most diversified portfolio for the given symbols using the Portfolio Optimizer API.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param covariance_type: The type of covariance matrix to use, either 'standard' or 'exponential', defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting, between 0 and 1. Only used if covariance_type='exponential'.\n",
    "        :type decay_factor: float, optional\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The optimized portfolio weights as a Pandas DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        if covariance_type == 'standard':\n",
    "            matrix = self._get_covariance_matrix(symbols, lookback, returns)\n",
    "        elif covariance_type == 'exponential':\n",
    "            matrix = self._get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "        else:\n",
    "            raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "        data = {\n",
    "            \"assets\": len(symbols),\n",
    "            \"assetsCovarianceMatrix\": matrix.values.tolist()\n",
    "        }\n",
    "\n",
    "        endpoint = \"/portfolio/optimization/most-diversified\"\n",
    "        response = self._make_request(endpoint, method=\"POST\", data=data)\n",
    "\n",
    "        weights = response['assetsWeights']\n",
    "        df = pd.DataFrame({'symbol': symbols, 'weight': weights}).set_index('symbol')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def construct_minimum_variance_portfolio(self, symbols: List[str], lookback: int,\n",
    "                                covariance_type: str = 'standard',\n",
    "                                decay_factor: float = 0.94,\n",
    "                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculates the minimum variance portfolio for the given symbols using the Portfolio Optimizer API.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param covariance_type: The type of covariance matrix to use, either 'standard' or 'exponential', defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting, between 0 and 1. Only used if covariance_type='exponential'.\n",
    "        :type decay_factor: float, optional\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The optimized portfolio weights as a Pandas DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        if covariance_type == 'standard':\n",
    "            matrix = self._get_covariance_matrix(symbols, lookback, returns)\n",
    "        elif covariance_type == 'exponential':\n",
    "            matrix = self._get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "        else:\n",
    "            raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "        data = {\n",
    "            \"assets\": len(symbols),\n",
    "            \"assetsCovarianceMatrix\": matrix.values.tolist()\n",
    "        }\n",
    "\n",
    "        endpoint = \"/portfolio/optimization/minimum-variance\"\n",
    "        response = self._make_request(endpoint, method=\"POST\", data=data)\n",
    "\n",
    "        weights = response['assetsWeights']\n",
    "        df = pd.DataFrame({'symbol': symbols, 'weight': weights}).set_index('symbol')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _async_get_covariance_matrix(self, symbols: List[str], lookback: int, returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves the covariance matrix of the given symbols.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The covariance matrix as a DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        returns = returns[symbols].tail(lookback)\n",
    "        matrix = returns.cov()\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    async def _async_get_exponential_covariance_matrix(self, symbols: List[str], lookback: int, decay_factor: float, returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves the exponentially weighted covariance matrix for a list of assets.\n",
    "\n",
    "        :param symbols: List of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting, between 0 and 1.\n",
    "        :type decay_factor: float\n",
    "        :param returns: Optional user-provided returns DataFrame, defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :return: The exponentially weighted covariance matrix as a DataFrame.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        returns = returns[symbols].tail(lookback)\n",
    "\n",
    "        data = {\n",
    "            \"assets\": [\n",
    "                {\"assetReturns\": returns[col].tolist()}\n",
    "                for col in returns.columns\n",
    "            ],\n",
    "            \"decayFactor\": decay_factor\n",
    "        }\n",
    "\n",
    "        endpoint = '/assets/covariance/matrix/exponentially-weighted'\n",
    "\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(url=self._base_url + endpoint, headers=self._headers, json=data) as r:\n",
    "\n",
    "                try:\n",
    "                    r.raise_for_status()\n",
    "                except:\n",
    "                    print(f\"Response text: {await r.text()}\")\n",
    "                    r.raise_for_status()\n",
    "                    \n",
    "                response = await r.json()\n",
    "\n",
    "        matrix = pd.DataFrame(response['assetsCovarianceMatrix'], index=symbols, columns=symbols)\n",
    "\n",
    "        return matrix\n",
    "\n",
    "\n",
    "    async def backtest_equal_risk_contributions_portfolio(self,\n",
    "                                                         symbols: List[str],\n",
    "                                                         lookback: int, \n",
    "                                                         covariance_type: str = 'standard', \n",
    "                                                         decay_factor: float = 0.94,\n",
    "                                                         frequency: str = 'month_start',\n",
    "                                                         method='any', \n",
    "                                                         start_equity: float = 100000,\n",
    "                                                         benchmark: str = 'SPY',\n",
    "                                                         fee: float = 0.0,\n",
    "                                                         returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Backtests an equal risk contributions portfolio over a specified period.\n",
    "\n",
    "        :param symbols: A list of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param frequency: The frequency of the returns data, either 'daily', 'weekly', or 'monthly'.\n",
    "        :type frequency: str\n",
    "        :param covariance_type: The type of covariance matrix to use in optimization, either 'standard' or 'exponential'. Defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting. Defaults to 0.94.\n",
    "        :type decay_factor: float, optional\n",
    "        :param frequency: The rebalance frequency for the backtest, either 'day', 'week_start', 'week_end', 'month_start', 'month_end', 'quarter_start', 'quarter_end', 'year_start', or 'year_end'. Defaults to 'month_start'.\n",
    "        :type frequency: str, optional\n",
    "        :param method: Whether to start the backtest when 'all' symbols have sufficient lookback data, or when 'any' symbol has sufficient lookback data. Defaults to 'any'.\n",
    "        :type method: str, optional\n",
    "        :param returns: User-provided returns DataFrame. Defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :param date_asset_pair_list: A list of tuples containing dates and their respective asset lists. Defaults to None.\n",
    "        :type date_asset_pair_list: List[Tuple[List[str], str]], optional\n",
    "        :return: DataFrame with portfolio data for each period.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        async def _async_single_portfolio_optimization(\n",
    "                                                symbols: List[str],\n",
    "                                                lookback: int,\n",
    "                                                covariance_type: str = 'standard',\n",
    "                                                decay_factor: float = 0.94,\n",
    "                                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            \n",
    "            if covariance_type == 'standard':\n",
    "                matrix = self._async_get_covariance_matrix(symbols, lookback, returns)\n",
    "            elif covariance_type == 'exponential':\n",
    "                matrix = await self._async_get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "            else:\n",
    "                raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "            data = {\n",
    "                \"assets\": len(symbols),\n",
    "                \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "                \"constraints\": {}\n",
    "            }\n",
    "\n",
    "            endpoint = \"/portfolio/optimization/equal-risk-contributions\"\n",
    "\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(url=self._base_url + endpoint, headers=self._headers, json=data) as r:\n",
    "                    if r.raise_for_status():\n",
    "                        print(f\"Error retrieving equal risk contributions portfolio: {await r.text()}\")\n",
    "                    else:\n",
    "                        response = await r.json()\n",
    "\n",
    "            weights = response['assetsWeights']\n",
    "\n",
    "            return weights\n",
    "\n",
    "        async def _call_optimization_function(symbols: List[str], returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            return await _async_single_portfolio_optimization(symbols=symbols, \n",
    "                                                              lookback=lookback, \n",
    "                                                              covariance_type=covariance_type, \n",
    "                                                              decay_factor=decay_factor, \n",
    "                                                              returns=returns)\n",
    "\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        position_history = self._get_position_history(symbols, lookback, frequency, method)\n",
    "\n",
    "        date_symbol_pair_list = [(date,symbols.dropna().tolist()) for date,symbols in position_history.iterrows()]\n",
    "\n",
    "        tasks = [_call_optimization_function(symbols, returns.shift(1).loc[:date]) for date, symbols in date_symbol_pair_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        weights = pd.DataFrame(results, index=position_history.index).fillna(0.0)\n",
    "        weights.columns = [f'weight_{i + 1}' for i in range(len(symbols))]\n",
    "        weights_history = pd.concat([position_history,weights],axis=1)\n",
    "\n",
    "        backtest = self._generate_portfolio_equity_curve(weights_history, returns, start_equity, fee)\n",
    "        benchmark_equity_curve = self._generate_benchmark_equity_curve(benchmark,start_equity,backtest.index.min(),backtest.index.max())\n",
    "        backtest = backtest.join(benchmark_equity_curve.to_frame(),how='left').ffill().bfill()\n",
    "\n",
    "        return backtest\n",
    "    \n",
    "    async def backtest_hierarchical_risk_parity_portfolio(self,\n",
    "                                                        symbols: List[str],\n",
    "                                                        lookback: int, \n",
    "                                                        covariance_type: str = 'standard', \n",
    "                                                        decay_factor: float = 0.94,\n",
    "                                                        frequency: str = 'month_start',\n",
    "                                                        method='any', \n",
    "                                                        start_equity: float = 100000,\n",
    "                                                        benchmark: str = 'SPY',\n",
    "                                                        fee: float = 0.0,\n",
    "                                                        returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Backtests a hierarchical risk parity portfolio over a specified period.\n",
    "\n",
    "        :param symbols: A list of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param frequency: The frequency of the returns data, either 'daily', 'weekly', or 'monthly'.\n",
    "        :type frequency: str\n",
    "        :param covariance_type: The type of covariance matrix to use in optimization, either 'standard' or 'exponential'. Defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting. Defaults to 0.94.\n",
    "        :type decay_factor: float, optional\n",
    "        :param frequency: The rebalance frequency for the backtest, either 'day', 'week_start', 'week_end', 'month_start', 'month_end', 'quarter_start', 'quarter_end', 'year_start', or 'year_end'. Defaults to 'month_start'.\n",
    "        :type frequency: str, optional\n",
    "        :param method: Whether to start the backtest when 'all' symbols have sufficient lookback data, or when 'any' symbol has sufficient lookback data. Defaults to 'any'.\n",
    "        :type method: str, optional\n",
    "        :param returns: User-provided returns DataFrame. Defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :param date_asset_pair_list: A list of tuples containing dates and their respective asset lists. Defaults to None.\n",
    "        :type date_asset_pair_list: List[Tuple[List[str], str]], optional\n",
    "        :return: DataFrame with portfolio data for each period.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        async def _async_single_portfolio_optimization(\n",
    "                                                symbols: List[str],\n",
    "                                                lookback: int,\n",
    "                                                covariance_type: str = 'standard',\n",
    "                                                decay_factor: float = 0.94,\n",
    "                                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            \n",
    "            if covariance_type == 'standard':\n",
    "                matrix = self._async_get_covariance_matrix(symbols, lookback, returns)\n",
    "            elif covariance_type == 'exponential':\n",
    "                matrix = await self._async_get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "            else:\n",
    "                raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "            data = {\n",
    "                \"assets\": len(symbols),\n",
    "                \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "                \"constraints\": {}\n",
    "            }\n",
    "\n",
    "            endpoint = \"/portfolio/optimization/hierarchical-risk-parity\"\n",
    "\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(url=self._base_url + endpoint, headers=self._headers, json=data) as r:\n",
    "                    if r.raise_for_status():\n",
    "                        print(f\"Error retrieving equal risk contributions portfolio: {await r.text()}\")\n",
    "                    else:\n",
    "                        response = await r.json()\n",
    "\n",
    "            weights = response['assetsWeights']\n",
    "\n",
    "            return weights\n",
    "\n",
    "        async def _call_optimization_function(symbols: List[str], returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            return await _async_single_portfolio_optimization(symbols=symbols, \n",
    "                                                                lookback=lookback, \n",
    "                                                                covariance_type=covariance_type, \n",
    "                                                                decay_factor=decay_factor, \n",
    "                                                                returns=returns)\n",
    "\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        position_history = self._get_position_history(symbols, lookback, frequency, method)\n",
    "\n",
    "        date_symbol_pair_list = [(date,symbols.dropna().tolist()) for date,symbols in position_history.iterrows()]\n",
    "\n",
    "        tasks = [_call_optimization_function(symbols, returns.shift(1).loc[:date]) for date, symbols in date_symbol_pair_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        weights = pd.DataFrame(results, index=position_history.index).fillna(0.0)\n",
    "        weights.columns = [f'weight_{i + 1}' for i in range(len(symbols))]\n",
    "        weights_history = pd.concat([position_history,weights],axis=1)\n",
    "\n",
    "        backtest = self._generate_portfolio_equity_curve(weights_history, returns, start_equity, fee)\n",
    "        benchmark_equity_curve = self._generate_benchmark_equity_curve(benchmark,start_equity,backtest.index.min(),backtest.index.max())\n",
    "        backtest = backtest.join(benchmark_equity_curve.to_frame(),how='left').ffill().bfill()\n",
    "\n",
    "        return backtest\n",
    "    \n",
    "    async def backtest_hierarchical_risk_parity_cluster_based_portfolio(self,\n",
    "                                                    symbols: List[str],\n",
    "                                                    lookback: int, \n",
    "                                                    covariance_type: str = 'standard', \n",
    "                                                    decay_factor: float = 0.94,\n",
    "                                                    frequency: str = 'month_start',\n",
    "                                                    method='any', \n",
    "                                                    start_equity: float = 100000,\n",
    "                                                    benchmark: str = 'SPY',\n",
    "                                                    fee: float = 0.0,\n",
    "                                                    returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Backtests a hierarchical risk parity clustering-based portfolio over a specified period.\n",
    "\n",
    "        :param symbols: A list of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param frequency: The frequency of the returns data, either 'daily', 'weekly', or 'monthly'.\n",
    "        :type frequency: str\n",
    "        :param covariance_type: The type of covariance matrix to use in optimization, either 'standard' or 'exponential'. Defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting. Defaults to 0.94.\n",
    "        :type decay_factor: float, optional\n",
    "        :param frequency: The rebalance frequency for the backtest, either 'day', 'week_start', 'week_end', 'month_start', 'month_end', 'quarter_start', 'quarter_end', 'year_start', or 'year_end'. Defaults to 'month_start'.\n",
    "        :type frequency: str, optional\n",
    "        :param method: Whether to start the backtest when 'all' symbols have sufficient lookback data, or when 'any' symbol has sufficient lookback data. Defaults to 'any'.\n",
    "        :type method: str, optional\n",
    "        :param returns: User-provided returns DataFrame. Defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :param date_asset_pair_list: A list of tuples containing dates and their respective asset lists. Defaults to None.\n",
    "        :type date_asset_pair_list: List[Tuple[List[str], str]], optional\n",
    "        :return: DataFrame with portfolio data for each period.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        async def _async_single_portfolio_optimization(\n",
    "                                                symbols: List[str],\n",
    "                                                lookback: int,\n",
    "                                                covariance_type: str = 'standard',\n",
    "                                                decay_factor: float = 0.94,\n",
    "                                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            \n",
    "            if covariance_type == 'standard':\n",
    "                matrix = self._async_get_covariance_matrix(symbols, lookback, returns)\n",
    "            elif covariance_type == 'exponential':\n",
    "                matrix = await self._async_get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "            else:\n",
    "                raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "            data = {\n",
    "                \"assets\": len(symbols),\n",
    "                \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "                \"constraints\": {}\n",
    "            }\n",
    "\n",
    "            endpoint = \"/portfolio/optimization/hierarchical-risk-parity/clustering-based\"\n",
    "\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(url=self._base_url + endpoint, headers=self._headers, json=data) as r:\n",
    "                    if r.raise_for_status():\n",
    "                        print(f\"Error retrieving equal risk contributions portfolio: {await r.text()}\")\n",
    "                    else:\n",
    "                        response = await r.json()\n",
    "\n",
    "            weights = response['assetsWeights']\n",
    "\n",
    "            return weights\n",
    "\n",
    "        async def _call_optimization_function(symbols: List[str], returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            return await _async_single_portfolio_optimization(symbols=symbols, \n",
    "                                                                lookback=lookback, \n",
    "                                                                covariance_type=covariance_type, \n",
    "                                                                decay_factor=decay_factor, \n",
    "                                                                returns=returns)\n",
    "\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        position_history = self._get_position_history(symbols, lookback, frequency, method)\n",
    "\n",
    "        date_symbol_pair_list = [(date,symbols.dropna().tolist()) for date,symbols in position_history.iterrows()]\n",
    "\n",
    "        tasks = [_call_optimization_function(symbols, returns.shift(1).loc[:date]) for date, symbols in date_symbol_pair_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        weights = pd.DataFrame(results, index=position_history.index).fillna(0.0)\n",
    "        weights.columns = [f'weight_{i + 1}' for i in range(len(symbols))]\n",
    "        weights_history = pd.concat([position_history,weights],axis=1)\n",
    "\n",
    "        backtest = self._generate_portfolio_equity_curve(weights_history, returns, start_equity, fee)\n",
    "        benchmark_equity_curve = self._generate_benchmark_equity_curve(benchmark,start_equity,backtest.index.min(),backtest.index.max())\n",
    "        backtest = backtest.join(benchmark_equity_curve.to_frame(),how='left').ffill().bfill()\n",
    "\n",
    "        return backtest\n",
    "    \n",
    "    async def backtest_most_diversified_portfolio(self,\n",
    "                                                    symbols: List[str],\n",
    "                                                    lookback: int, \n",
    "                                                    covariance_type: str = 'standard', \n",
    "                                                    decay_factor: float = 0.94,\n",
    "                                                    frequency: str = 'month_start',\n",
    "                                                    method='any', \n",
    "                                                    start_equity: float = 100000,\n",
    "                                                    benchmark: str = 'SPY',\n",
    "                                                    fee: float = 0.0,\n",
    "                                                    returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Backtests a most diversified portfolio over a specified period.\n",
    "\n",
    "        :param symbols: A list of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param frequency: The frequency of the returns data, either 'daily', 'weekly', or 'monthly'.\n",
    "        :type frequency: str\n",
    "        :param covariance_type: The type of covariance matrix to use in optimization, either 'standard' or 'exponential'. Defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting. Defaults to 0.94.\n",
    "        :type decay_factor: float, optional\n",
    "        :param frequency: The rebalance frequency for the backtest, either 'day', 'week_start', 'week_end', 'month_start', 'month_end', 'quarter_start', 'quarter_end', 'year_start', or 'year_end'. Defaults to 'month_start'.\n",
    "        :type frequency: str, optional\n",
    "        :param method: Whether to start the backtest when 'all' symbols have sufficient lookback data, or when 'any' symbol has sufficient lookback data. Defaults to 'any'.\n",
    "        :type method: str, optional\n",
    "        :param returns: User-provided returns DataFrame. Defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :param date_asset_pair_list: A list of tuples containing dates and their respective asset lists. Defaults to None.\n",
    "        :type date_asset_pair_list: List[Tuple[List[str], str]], optional\n",
    "        :return: DataFrame with portfolio data for each period.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        async def _async_single_portfolio_optimization(\n",
    "                                                symbols: List[str],\n",
    "                                                lookback: int,\n",
    "                                                covariance_type: str = 'standard',\n",
    "                                                decay_factor: float = 0.94,\n",
    "                                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            \n",
    "            if covariance_type == 'standard':\n",
    "                matrix = self._async_get_covariance_matrix(symbols, lookback, returns)\n",
    "            elif covariance_type == 'exponential':\n",
    "                matrix = await self._async_get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "            else:\n",
    "                raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "            data = {\n",
    "                \"assets\": len(symbols),\n",
    "                \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "                \"constraints\": {}\n",
    "            }\n",
    "\n",
    "            endpoint = \"/portfolio/optimization/most-diversified\"\n",
    "\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(url=self._base_url + endpoint, headers=self._headers, json=data) as r:\n",
    "                    if r.raise_for_status():\n",
    "                        print(f\"Error retrieving equal risk contributions portfolio: {await r.text()}\")\n",
    "                    else:\n",
    "                        response = await r.json()\n",
    "\n",
    "            weights = response['assetsWeights']\n",
    "\n",
    "            return weights\n",
    "\n",
    "        async def _call_optimization_function(symbols: List[str], returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            return await _async_single_portfolio_optimization(symbols=symbols, \n",
    "                                                                lookback=lookback, \n",
    "                                                                covariance_type=covariance_type, \n",
    "                                                                decay_factor=decay_factor, \n",
    "                                                                returns=returns)\n",
    "\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        position_history = self._get_position_history(symbols, lookback, frequency, method)\n",
    "\n",
    "        date_symbol_pair_list = [(date,symbols.dropna().tolist()) for date,symbols in position_history.iterrows()]\n",
    "\n",
    "        tasks = [_call_optimization_function(symbols, returns.shift(1).loc[:date]) for date, symbols in date_symbol_pair_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        weights = pd.DataFrame(results, index=position_history.index).fillna(0.0)\n",
    "        weights.columns = [f'weight_{i + 1}' for i in range(len(symbols))]\n",
    "        weights_history = pd.concat([position_history,weights],axis=1)\n",
    "\n",
    "        backtest = self._generate_portfolio_equity_curve(weights_history, returns, start_equity, fee)\n",
    "        benchmark_equity_curve = self._generate_benchmark_equity_curve(benchmark,start_equity,backtest.index.min(),backtest.index.max())\n",
    "        backtest = backtest.join(benchmark_equity_curve.to_frame(),how='left').ffill().bfill()\n",
    "\n",
    "        return backtest\n",
    "    \n",
    "    async def backtest_minimum_variance_portfolio(self,\n",
    "                                                    symbols: List[str],\n",
    "                                                    lookback: int, \n",
    "                                                    covariance_type: str = 'standard', \n",
    "                                                    decay_factor: float = 0.94,\n",
    "                                                    frequency: str = 'month_start',\n",
    "                                                    method='any', \n",
    "                                                    start_equity: float = 100000,\n",
    "                                                    benchmark: str = 'SPY',\n",
    "                                                    fee: float = 0.0,\n",
    "                                                    returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Backtests a minimum variance portfolio over a specified period.\n",
    "\n",
    "        :param symbols: A list of stock symbols.\n",
    "        :type symbols: List[str]\n",
    "        :param lookback: The number of rows to consider from the returns DataFrame.\n",
    "        :type lookback: int\n",
    "        :param frequency: The frequency of the returns data, either 'daily', 'weekly', or 'monthly'.\n",
    "        :type frequency: str\n",
    "        :param covariance_type: The type of covariance matrix to use in optimization, either 'standard' or 'exponential'. Defaults to 'standard'.\n",
    "        :type covariance_type: str, optional\n",
    "        :param decay_factor: The decay factor to use in the exponential weighting. Defaults to 0.94.\n",
    "        :type decay_factor: float, optional\n",
    "        :param frequency: The rebalance frequency for the backtest, either 'day', 'week_start', 'week_end', 'month_start', 'month_end', 'quarter_start', 'quarter_end', 'year_start', or 'year_end'. Defaults to 'month_start'.\n",
    "        :type frequency: str, optional\n",
    "        :param method: Whether to start the backtest when 'all' symbols have sufficient lookback data, or when 'any' symbol has sufficient lookback data. Defaults to 'any'.\n",
    "        :type method: str, optional\n",
    "        :param returns: User-provided returns DataFrame. Defaults to None.\n",
    "        :type returns: pd.DataFrame, optional\n",
    "        :param date_asset_pair_list: A list of tuples containing dates and their respective asset lists. Defaults to None.\n",
    "        :type date_asset_pair_list: List[Tuple[List[str], str]], optional\n",
    "        :return: DataFrame with portfolio data for each period.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        async def _async_single_portfolio_optimization(\n",
    "                                                symbols: List[str],\n",
    "                                                lookback: int,\n",
    "                                                covariance_type: str = 'standard',\n",
    "                                                decay_factor: float = 0.94,\n",
    "                                                returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            \n",
    "            if covariance_type == 'standard':\n",
    "                matrix = self._async_get_covariance_matrix(symbols, lookback, returns)\n",
    "            elif covariance_type == 'exponential':\n",
    "                matrix = await self._async_get_exponential_covariance_matrix(symbols, lookback, decay_factor, returns)\n",
    "            else:\n",
    "                raise ValueError(\"covariance_type must be either 'standard' or 'exponential'\")\n",
    "\n",
    "            data = {\n",
    "                \"assets\": len(symbols),\n",
    "                \"assetsCovarianceMatrix\": matrix.values.tolist(),\n",
    "                \"constraints\": {}\n",
    "            }\n",
    "\n",
    "            endpoint = \"/portfolio/optimization/minimum-variance\"\n",
    "\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.post(url=self._base_url + endpoint, headers=self._headers, json=data) as r:\n",
    "                    if r.raise_for_status():\n",
    "                        print(f\"Error retrieving equal risk contributions portfolio: {await r.text()}\")\n",
    "                    else:\n",
    "                        response = await r.json()\n",
    "\n",
    "            weights = response['assetsWeights']\n",
    "\n",
    "            return weights\n",
    "\n",
    "        async def _call_optimization_function(symbols: List[str], returns: pd.DataFrame = None) -> pd.DataFrame:\n",
    "            return await _async_single_portfolio_optimization(symbols=symbols, \n",
    "                                                                lookback=lookback, \n",
    "                                                                covariance_type=covariance_type, \n",
    "                                                                decay_factor=decay_factor, \n",
    "                                                                returns=returns)\n",
    "\n",
    "        if not self._validate_returns_format(returns, symbols, lookback):\n",
    "            returns = self._get_asset_returns(symbols, lookback)\n",
    "\n",
    "        position_history = self._get_position_history(symbols, lookback, frequency, method)\n",
    "\n",
    "        date_symbol_pair_list = [(date,symbols.dropna().tolist()) for date,symbols in position_history.iterrows()]\n",
    "\n",
    "        tasks = [_call_optimization_function(symbols, returns.shift(1).loc[:date]) for date, symbols in date_symbol_pair_list]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        weights = pd.DataFrame(results, index=position_history.index).fillna(0.0)\n",
    "        weights.columns = [f'weight_{i + 1}' for i in range(len(symbols))]\n",
    "        weights_history = pd.concat([position_history,weights],axis=1)\n",
    "\n",
    "        backtest = self._generate_portfolio_equity_curve(weights_history, returns, start_equity, fee)\n",
    "        benchmark_equity_curve = self._generate_benchmark_equity_curve(benchmark,start_equity,backtest.index.min(),backtest.index.max())\n",
    "        backtest = backtest.join(benchmark_equity_curve.to_frame(),how='left').ffill().bfill()\n",
    "\n",
    "        return backtest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-optimizer-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
